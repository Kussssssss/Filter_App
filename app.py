import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

# Thi·∫øt l·∫≠p c·∫•u h√¨nh trang
st.set_page_config(
    page_title="·ª®ng d·ª•ng N√¢ng Cao Ch·∫•t L∆∞·ª£ng ·∫¢nh",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Ti√™u ƒë·ªÅ c·ªßa ·ª©ng d·ª•ng
st.title("üñºÔ∏è ·ª®ng d·ª•ng N√¢ng Cao Ch·∫•t L∆∞·ª£ng ·∫¢nh")

# Gi·ªõi thi·ªáu
st.markdown("""
Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng n√¢ng cao ch·∫•t l∆∞·ª£ng ·∫£nh. B·∫°n c√≥ th·ªÉ:
- T·∫£i l√™n m·ªôt ·∫£nh t·ª´ m√°y t√≠nh c·ªßa b·∫°n.
- √Åp d·ª•ng c√°c b·ªô l·ªçc v√† t√≠nh nƒÉng ƒë·ªÉ c·∫£i thi·ªán v√† ph√¢n t√≠ch ·∫£nh.
""")

# Sidebar - T·∫£i ·∫£nh v√† ch·ªçn b·ªô l·ªçc
st.sidebar.title("üéõÔ∏è T√πy ch·ªçn")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn m·ªôt ·∫£nh...", type=["jpg", "jpeg", "png"])

# ƒê·ªãnh nghƒ©a k√≠ch th∆∞·ªõc hi·ªÉn th·ªã ·∫£nh c·ªë ƒë·ªãnh
DISPLAY_WIDTH = 300  # B·∫°n c√≥ th·ªÉ thay ƒë·ªïi gi√° tr·ªã n√†y theo √Ω mu·ªën

if uploaded_file is not None:
    # ƒê·ªçc ·∫£nh t·ª´ file t·∫£i l√™n
    image = Image.open(uploaded_file)
    # Chuy·ªÉn ƒë·ªïi ·∫£nh v·ªÅ RGB n·∫øu ·∫£nh l√† RGBA
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    img_array = np.array(image)
    img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

    # Hi·ªÉn th·ªã ·∫£nh g·ªëc v·ªõi k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh
    st.subheader("·∫¢nh G·ªëc")
    resized_image = image.resize((DISPLAY_WIDTH, int(image.height * DISPLAY_WIDTH / image.width)))
    st.image(resized_image, caption='·∫¢nh G·ªëc', use_column_width=False)

    # Ch·ªçn c√°c b·ªô l·ªçc
    st.sidebar.subheader("Ch·ªçn c√°c b·ªô l·ªçc mu·ªën √°p d·ª•ng")

    filter_options = ["Brightness/Contrast", "Histogram Equalization", "CLAHE", "Denoising", "Sharpening", "Blurring", "Edge Detection", "Morphological Operations"]
    selected_filters = st.sidebar.multiselect("Ch·ªçn b·ªô l·ªçc:", filter_options)

    # Kh·ªüi t·∫°o bi·∫øn l∆∞u ·∫£nh hi·ªán t·∫°i
    current_image = img.copy()
    processed_images = []
    captions = []

    # √Åp d·ª•ng c√°c b·ªô l·ªçc ƒë∆∞·ª£c ch·ªçn
    for filter_name in selected_filters:
        if filter_name == "Brightness/Contrast":
            with st.sidebar.expander("Brightness & Contrast"):
                brightness = st.slider("ƒê·ªô s√°ng", -100, 100, 0, key='brightness')
                contrast = st.slider("ƒê·ªô t∆∞∆°ng ph·∫£n", -100, 100, 0, key='contrast')

            beta = brightness
            alpha = contrast / 100 + 1  # contrast t·ª´ -100 ƒë·∫øn 100, alpha t·ª´ 0 ƒë·∫øn 2

            adjusted = cv2.convertScaleAbs(current_image, alpha=alpha, beta=beta)
            current_image = adjusted
            processed_images.append(cv2.cvtColor(adjusted, cv2.COLOR_BGR2RGB))
            captions.append("Brightness/Contrast Adjusted")

        elif filter_name == "Histogram Equalization":
            # Kh√¥ng c·∫ßn tham s·ªë
            # Chuy·ªÉn ƒë·ªïi sang YCrCb
            img_y_cr_cb = cv2.cvtColor(current_image, cv2.COLOR_BGR2YCrCb)
            # T√°ch c√°c k√™nh
            y, cr, cb = cv2.split(img_y_cr_cb)
            # √Åp d·ª•ng equalization tr√™n k√™nh Y
            y_eq = cv2.equalizeHist(y)
            # G·ªôp c√°c k√™nh l·∫°i
            img_y_cr_cb_eq = cv2.merge((y_eq, cr, cb))
            # Chuy·ªÉn ƒë·ªïi l·∫°i sang BGR
            img_eq = cv2.cvtColor(img_y_cr_cb_eq, cv2.COLOR_YCrCb2BGR)
            current_image = img_eq
            processed_images.append(cv2.cvtColor(img_eq, cv2.COLOR_BGR2RGB))
            captions.append("Histogram Equalization")

        elif filter_name == "CLAHE":
            with st.sidebar.expander("CLAHE"):
                clip_limit = st.slider("Clip Limit", 1.0, 10.0, 2.0, key='clip_limit')
                tile_grid_size = st.slider("Tile Grid Size", 1, 16, 8, key='tile_grid_size')

            # Chuy·ªÉn ƒë·ªïi sang LAB
            lab = cv2.cvtColor(current_image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            # √Åp d·ª•ng CLAHE tr√™n k√™nh L
            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_grid_size, tile_grid_size))
            l_clahe = clahe.apply(l)
            # G·ªôp c√°c k√™nh l·∫°i
            lab_clahe = cv2.merge((l_clahe, a, b))
            # Chuy·ªÉn ƒë·ªïi l·∫°i sang BGR
            img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)
            current_image = img_clahe
            processed_images.append(cv2.cvtColor(img_clahe, cv2.COLOR_BGR2RGB))
            captions.append("CLAHE Applied")

        elif filter_name == "Denoising":
            with st.sidebar.expander("Denoising"):
                h = st.slider('Gi√° tr·ªã h', 0, 50, 10, key='h')
                hColor = st.slider('Gi√° tr·ªã hColor', 0, 50, 10, key='hColor')
                templateWindowSize = st.slider('K√≠ch th∆∞·ªõc templateWindowSize', 1, 10, 7, key='templateWindowSize')
                searchWindowSize = st.slider('K√≠ch th∆∞·ªõc searchWindowSize', 1, 30, 21, key='searchWindowSize')

            denoised = cv2.fastNlMeansDenoisingColored(
                current_image, None, h=h, hColor=hColor,
                templateWindowSize=templateWindowSize, searchWindowSize=searchWindowSize
            )
            current_image = denoised
            processed_images.append(cv2.cvtColor(denoised, cv2.COLOR_BGR2RGB))
            captions.append("Denoised Image")

        elif filter_name == "Sharpening":
            # Kh√¥ng c·∫ßn tham s·ªë
            kernel_sharpening = np.array([[-1,-1,-1],
                                          [-1, 9,-1],
                                          [-1,-1,-1]])
            sharpened = cv2.filter2D(current_image, -1, kernel_sharpening)
            current_image = sharpened
            processed_images.append(cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB))
            captions.append("Sharpened Image")

        elif filter_name == "Blurring":
            with st.sidebar.expander("Blurring"):
                blur_type = st.selectbox("Ch·ªçn lo·∫°i blur:", ["Average", "Gaussian", "Median", "Bilateral"], key='blur_type')
                if blur_type == "Average":
                    ksize = st.slider('K√≠ch th∆∞·ªõc kernel', 1, 15, 5, step=2, key='avg_ksize')
                    blurred = cv2.blur(current_image, (ksize, ksize))
                elif blur_type == "Gaussian":
                    ksize = st.slider('K√≠ch th∆∞·ªõc kernel', 1, 15, 5, step=2, key='gauss_ksize')
                    blurred = cv2.GaussianBlur(current_image, (ksize, ksize), 0)
                elif blur_type == "Median":
                    ksize = st.slider('K√≠ch th∆∞·ªõc kernel', 1, 15, 5, step=2, key='median_ksize')
                    blurred = cv2.medianBlur(current_image, ksize)
                elif blur_type == "Bilateral":
                    diameter = st.slider('ƒê∆∞·ªùng k√≠nh pixel', 1, 15, 9, step=2, key='bilat_diameter')
                    sigmaColor = st.slider('Sigma Color', 1, 200, 75, key='bilat_sigmaColor')
                    sigmaSpace = st.slider('Sigma Space', 1, 200, 75, key='bilat_sigmaSpace')
                    blurred = cv2.bilateralFilter(current_image, diameter, sigmaColor, sigmaSpace)
            current_image = blurred
            processed_images.append(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))
            captions.append(f"{blur_type} Blurred")

        elif filter_name == "Edge Detection":
            with st.sidebar.expander("Edge Detection"):
                edge_method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p:", ["Sobel", "Canny"], key='edge_method')
                if edge_method == "Sobel":
                    ksize = st.slider('K√≠ch th∆∞·ªõc kernel', 1, 7, 5, step=2, key='sobel_ksize')
                elif edge_method == "Canny":
                    canny_threshold1 = st.slider('Ng∆∞·ª°ng d∆∞·ªõi', 0, 255, 100, key='canny_thresh1')
                    canny_threshold2 = st.slider('Ng∆∞·ª°ng tr√™n', 0, 255, 200, key='canny_thresh2')

            gray_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)

            if edge_method == "Sobel":
                sobelx = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=ksize)
                sobely = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=ksize)
                sobel = cv2.magnitude(sobelx, sobely)
                sobel = np.uint8(np.absolute(sobel))
                edge_img = sobel
                captions.append("Sobel Edge")
            elif edge_method == "Canny":
                edge_img = cv2.Canny(gray_image, canny_threshold1, canny_threshold2)
                captions.append("Canny Edge")

            # Chuy·ªÉn ƒë·ªïi ·∫£nh c·∫°nh sang RGB ƒë·ªÉ hi·ªÉn th·ªã
            edge_img_rgb = cv2.cvtColor(edge_img, cv2.COLOR_GRAY2RGB)
            current_image = edge_img_rgb
            processed_images.append(edge_img_rgb)
            # Edge detection l√† b∆∞·ªõc cu·ªëi c√πng
            break  # D·ª´ng √°p d·ª•ng c√°c b·ªô l·ªçc ti·∫øp theo

        elif filter_name == "Morphological Operations":
            with st.sidebar.expander("Morphological Operations"):
                operation = st.selectbox("Ch·ªçn lo·∫°i:", ["Erosion", "Dilation", "Opening", "Closing"], key='morph_operation')
                kernel_size = st.slider('K√≠ch th∆∞·ªõc kernel', 1, 15, 5, step=2, key='morph_kernel_size')

            kernel = np.ones((kernel_size, kernel_size), np.uint8)
            gray_image = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)

            if operation == "Erosion":
                result = cv2.erode(gray_image, kernel, iterations=1)
                captions.append("Erosion")
            elif operation == "Dilation":
                result = cv2.dilate(gray_image, kernel, iterations=1)
                captions.append("Dilation")
            elif operation == "Opening":
                result = cv2.morphologyEx(gray_image, cv2.MORPH_OPEN, kernel)
                captions.append("Opening")
            elif operation == "Closing":
                result = cv2.morphologyEx(gray_image, cv2.MORPH_CLOSE, kernel)
                captions.append("Closing")

            # Chuy·ªÉn ƒë·ªïi ·∫£nh k·∫øt qu·∫£ sang RGB ƒë·ªÉ hi·ªÉn th·ªã
            result_rgb = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)
            current_image = result_rgb
            processed_images.append(result_rgb)

    # Hi·ªÉn th·ªã ·∫£nh sau khi √°p d·ª•ng c√°c b·ªô l·ªçc
    if processed_images:
        st.subheader("K·∫øt qu·∫£ sau khi √°p d·ª•ng c√°c b·ªô l·ªçc")
        num_images = len(processed_images)
        cols = st.columns(num_images)
        for idx, (img_to_show, caption) in enumerate(zip(processed_images, captions)):
            with cols[idx]:
                # Resize ·∫£nh ƒë·ªÉ hi·ªÉn th·ªã ƒë·ªìng nh·∫•t
                display_img = Image.fromarray(img_to_show)
                display_img = display_img.resize((DISPLAY_WIDTH, int(display_img.height * DISPLAY_WIDTH / display_img.width)))
                st.image(display_img, caption=caption, use_column_width=False)
                # Th√™m n√∫t t·∫£i xu·ªëng
                buf = io.BytesIO()
                display_img.save(buf, format="PNG")
                byte_im = buf.getvalue()
                st.download_button(
                    label="üì• T·∫£i xu·ªëng",
                    data=byte_im,
                    file_name=f"{caption.replace(' ', '_').lower()}.png",
                    mime="image/png"
                )

else:
    st.write("Vui l√≤ng t·∫£i l√™n m·ªôt ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# Th√™m ph·∫ßn ch√¢n trang
st.markdown("""
---
üìù **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng**:
1. T·∫£i l√™n m·ªôt ·∫£nh t·ª´ m√°y t√≠nh c·ªßa b·∫°n b·∫±ng c√°ch s·ª≠ d·ª•ng n√∫t "Browse files" ·ªü thanh b√™n tr√°i.
2. Ch·ªçn c√°c b·ªô l·ªçc b·∫°n mu·ªën √°p d·ª•ng.
3. ƒêi·ªÅu ch·ªânh c√°c tham s·ªë cho t·ª´ng b·ªô l·ªçc n·∫øu c·∫ßn.
4. **K·∫øt qu·∫£ s·∫Ω t·ª± ƒë·ªông c·∫≠p nh·∫≠t khi b·∫°n thay ƒë·ªïi tham s·ªë.**
5. B·∫°n c√≥ th·ªÉ t·∫£i xu·ªëng ·∫£nh ƒë√£ x·ª≠ l√Ω b·∫±ng c√°ch nh·∫•n n√∫t "T·∫£i xu·ªëng" d∆∞·ªõi m·ªói ·∫£nh.
""")
